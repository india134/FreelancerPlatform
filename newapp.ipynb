{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc5975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c22d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('freelancer_job_postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f501376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectId</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>client_state</th>\n",
       "      <th>client_country</th>\n",
       "      <th>client_average_rating</th>\n",
       "      <th>client_review_count</th>\n",
       "      <th>min_price</th>\n",
       "      <th>max_price</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>currency</th>\n",
       "      <th>rate_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37426471</td>\n",
       "      <td>development and implementation of a federated ...</td>\n",
       "      <td>please bid only if you are ready to do the wor...</td>\n",
       "      <td>['algorithm', 'java', 'python', 'machine learn...</td>\n",
       "      <td>Heilbronn</td>\n",
       "      <td>Germany</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>19.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37421546</td>\n",
       "      <td>Data Entry  -- 2</td>\n",
       "      <td>Project Title: Data Entry - Data Analysis in E...</td>\n",
       "      <td>['excel', 'statistical analysis', 'statistics'...</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>India</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "      <td>1250</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>hourly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37400492</td>\n",
       "      <td>Data Scrap</td>\n",
       "      <td>I am looking for a freelancer who can help me ...</td>\n",
       "      <td>['web scraping', 'data mining', 'data entry', ...</td>\n",
       "      <td>Eaubonne</td>\n",
       "      <td>France</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>140.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37404568</td>\n",
       "      <td>Big Data Project</td>\n",
       "      <td>Store Sales Data Analysis: A Data Engineering ...</td>\n",
       "      <td>['big data sales', 'data science', 'data minin...</td>\n",
       "      <td>Mundra</td>\n",
       "      <td>India</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>5500</td>\n",
       "      <td>5250.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37397423</td>\n",
       "      <td>Virtual Assistant / Research Assistant</td>\n",
       "      <td>Job Description: I am seeking a Virtual Assist...</td>\n",
       "      <td>['data entry', 'virtual assistant', 'web searc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>hourly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188</th>\n",
       "      <td>31183091</td>\n",
       "      <td>Computer Vision / Feature Extraction from Aeri...</td>\n",
       "      <td>Looking for an experienced computer vision / f...</td>\n",
       "      <td>['python', 'deep learning', 'computer vision',...</td>\n",
       "      <td>Buenos Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>140.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9189</th>\n",
       "      <td>31184739</td>\n",
       "      <td>Database and software analysis</td>\n",
       "      <td>I need a freelancer who's proficient in micros...</td>\n",
       "      <td>['data processing']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>750</td>\n",
       "      <td>500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9190</th>\n",
       "      <td>31185401</td>\n",
       "      <td>Business Analyst (Strategic Projects)  -- 2</td>\n",
       "      <td>Role Purpose  The role’s purpose is to superch...</td>\n",
       "      <td>['python', 'business analysis', 'financial ana...</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Australia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>AUD</td>\n",
       "      <td>hourly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>31189015</td>\n",
       "      <td>AI developer needed</td>\n",
       "      <td>We are an italian startup seeking for a machin...</td>\n",
       "      <td>['data analysis', 'machine learning (ml)', 'py...</td>\n",
       "      <td>Modena</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9192</th>\n",
       "      <td>31192514</td>\n",
       "      <td>URGENT- GCP-CloudMigration-8-12 years</td>\n",
       "      <td>Cloud Migration Assessment Specialist Experien...</td>\n",
       "      <td>['google cloud platform', 'data warehousing', ...</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>India</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>750</td>\n",
       "      <td>575.0</td>\n",
       "      <td>INR</td>\n",
       "      <td>hourly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9193 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      projectId                                          job_title  \\\n",
       "0      37426471  development and implementation of a federated ...   \n",
       "1      37421546                                   Data Entry  -- 2   \n",
       "2      37400492                                         Data Scrap   \n",
       "3      37404568                                   Big Data Project   \n",
       "4      37397423            Virtual Assistant / Research Assistant    \n",
       "...         ...                                                ...   \n",
       "9188   31183091  Computer Vision / Feature Extraction from Aeri...   \n",
       "9189   31184739                   Database and software analysis     \n",
       "9190   31185401        Business Analyst (Strategic Projects)  -- 2   \n",
       "9191   31189015                                AI developer needed   \n",
       "9192   31192514             URGENT- GCP-CloudMigration-8-12 years    \n",
       "\n",
       "                                        job_description  \\\n",
       "0     please bid only if you are ready to do the wor...   \n",
       "1     Project Title: Data Entry - Data Analysis in E...   \n",
       "2     I am looking for a freelancer who can help me ...   \n",
       "3     Store Sales Data Analysis: A Data Engineering ...   \n",
       "4     Job Description: I am seeking a Virtual Assist...   \n",
       "...                                                 ...   \n",
       "9188  Looking for an experienced computer vision / f...   \n",
       "9189  I need a freelancer who's proficient in micros...   \n",
       "9190  Role Purpose  The role’s purpose is to superch...   \n",
       "9191  We are an italian startup seeking for a machin...   \n",
       "9192  Cloud Migration Assessment Specialist Experien...   \n",
       "\n",
       "                                                   tags  client_state  \\\n",
       "0     ['algorithm', 'java', 'python', 'machine learn...     Heilbronn   \n",
       "1     ['excel', 'statistical analysis', 'statistics'...        Nagpur   \n",
       "2     ['web scraping', 'data mining', 'data entry', ...      Eaubonne   \n",
       "3     ['big data sales', 'data science', 'data minin...        Mundra   \n",
       "4     ['data entry', 'virtual assistant', 'web searc...           NaN   \n",
       "...                                                 ...           ...   \n",
       "9188  ['python', 'deep learning', 'computer vision',...  Buenos Aires   \n",
       "9189                                ['data processing']           NaN   \n",
       "9190  ['python', 'business analysis', 'financial ana...        Sydney   \n",
       "9191  ['data analysis', 'machine learning (ml)', 'py...        Modena   \n",
       "9192  ['google cloud platform', 'data warehousing', ...    Coimbatore   \n",
       "\n",
       "      client_country  client_average_rating  client_review_count  min_price  \\\n",
       "0            Germany                    5.0                   17          8   \n",
       "1              India                    0.0                    0        750   \n",
       "2             France                    5.0                    1         30   \n",
       "3              India                    5.0                    2       5000   \n",
       "4      United States                    0.0                    0          5   \n",
       "...              ...                    ...                  ...        ...   \n",
       "9188       Argentina                    5.0                   12         30   \n",
       "9189  United Kingdom                    0.0                    0        250   \n",
       "9190       Australia                    5.0                   39         15   \n",
       "9191           Italy                    0.0                    0       3000   \n",
       "9192           India                    0.0                    0        400   \n",
       "\n",
       "      max_price  avg_price currency rate_type  \n",
       "0            30       19.0      EUR     fixed  \n",
       "1          1250     1000.0      INR    hourly  \n",
       "2           250      140.0      EUR     fixed  \n",
       "3          5500     5250.0      INR     fixed  \n",
       "4            15       10.0      USD    hourly  \n",
       "...         ...        ...      ...       ...  \n",
       "9188        250      140.0      USD     fixed  \n",
       "9189        750      500.0      USD     fixed  \n",
       "9190         25       20.0      AUD    hourly  \n",
       "9191       5000     4000.0      EUR     fixed  \n",
       "9192        750      575.0      INR    hourly  \n",
       "\n",
       "[9193 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36986257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   min_price_usd  max_price_usd  avg_price_usd\n",
      "0            8.8           33.0           20.9\n",
      "1            9.0           15.0           12.0\n",
      "2           33.0          275.0          154.0\n",
      "3           60.0           66.0           63.0\n",
      "4            5.0           15.0           10.0\n"
     ]
    }
   ],
   "source": [
    "# Example fixed exchange rates (as of Aug 2025 approx — update with latest)\n",
    "exchange_rates = {\n",
    "    \"USD\": 1.0,\n",
    "    \"EUR\": 1.10,   # 1 EUR = 1.10 USD\n",
    "    \"INR\": 0.012,  # 1 INR = 0.012 USD\n",
    "    \"SGD\": 0.74,   # 1 SGD = 0.74 USD\n",
    "    \"GBP\": 1.27,   # 1 GBP = 1.27 USD\n",
    "    \"AUD\": 0.67,   # 1 AUD = 0.67 USD\n",
    "    \"HKD\": 0.13,   # 1 HKD = 0.13 USD\n",
    "    \"CAD\": 0.73,   # 1 CAD = 0.73 USD\n",
    "    \"NZD\": 0.61    # 1 NZD = 0.61 USD\n",
    "}\n",
    "\n",
    "# Function to convert given price column to USD\n",
    "def convert_to_usd(row, column):\n",
    "    rate = exchange_rates.get(row[\"currency\"], 1.0)\n",
    "    return row[column] * rate\n",
    "\n",
    "# Convert min_price, max_price, avg_price to USD\n",
    "for col in [\"min_price\", \"max_price\", \"avg_price\"]:\n",
    "    data[f\"{col}_usd\"] = data.apply(lambda row: convert_to_usd(row, col), axis=1)\n",
    "\n",
    "# Update currency column to USD\n",
    "data[\"currency\"] = \"USD\"\n",
    "\n",
    "# Preview\n",
    "print(data[[\"min_price_usd\", \"max_price_usd\", \"avg_price_usd\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917bde5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['currency','projectId','client_state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d787e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"min_price\", \"max_price\", \"avg_price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d590b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['client_average_rating','client_review_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a079fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace empty strings, \"NA\", \"nan\", whitespace with NaN\n",
    "data['client_country'] = data['client_country'].replace(\n",
    "    [\"\", \" \", \"NA\", \"NAN\", \"nan\"], np.nan\n",
    ")\n",
    "\n",
    "# Drop rows where client_country is NaN\n",
    "data = data.dropna(subset=['client_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e47014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# One-hot encode rate_type\n",
    "data = pd.get_dummies(data, columns=['rate_type'], prefix='rate')\n",
    "\n",
    "# Check result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9239981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rate_fixed  rate_hourly\n",
      "0           1            0\n",
      "1           0            1\n",
      "2           1            0\n",
      "3           1            0\n",
      "4           0            1\n"
     ]
    }
   ],
   "source": [
    "# Convert boolean columns to integers\n",
    "data['rate_fixed'] = data['rate_fixed'].astype(int)\n",
    "data['rate_hourly'] = data['rate_hourly'].astype(int)\n",
    "\n",
    "print(data[['rate_fixed','rate_hourly']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accd1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                tags  \\\n",
      "0  ['algorithm', 'java', 'python', 'machine learn...   \n",
      "1  ['excel', 'statistical analysis', 'statistics'...   \n",
      "2  ['web scraping', 'data mining', 'data entry', ...   \n",
      "3  ['big data sales', 'data science', 'data minin...   \n",
      "4  ['data entry', 'virtual assistant', 'web searc...   \n",
      "\n",
      "                                          tags_clean  \n",
      "0  algorithm, java, python, machine learning (ml)...  \n",
      "1  excel, statistical analysis, statistics, spss ...  \n",
      "2  web scraping, data mining, data entry, excel, ...  \n",
      "3  big data sales, data science, data mining, sta...  \n",
      "4  data entry, virtual assistant, web search, exc...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your dataset\n",
    "\n",
    "\n",
    "# Function to clean and convert tags list → string\n",
    "def process_tags(tag_str):\n",
    "    try:\n",
    "        # Convert string representation of list into actual list\n",
    "        tag_list = ast.literal_eval(tag_str)\n",
    "        \n",
    "        # Join list elements into a comma-separated string\n",
    "        if isinstance(tag_list, list):\n",
    "            return \", \".join([str(t).strip() for t in tag_list])\n",
    "        else:\n",
    "            return str(tag_str)\n",
    "    except:\n",
    "        return str(tag_str)  # fallback if not list-like\n",
    "\n",
    "# Apply function to your tags column\n",
    "data[\"tags_clean\"] = data[\"tags\"].apply(process_tags)\n",
    "\n",
    "# Check result\n",
    "print(data[[\"tags\", \"tags_clean\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e15566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['tags'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb7cf8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77141263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI\\Mastery series\\Projects Aug-Sep 2025\\freelancecontracts\\freelancer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8fe916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.8.0+cpu\n",
      "CUDA version: None\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28136171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 288/288 [26:01<00:00,  5.42s/it]    \n"
     ]
    }
   ],
   "source": [
    "df[\"text_for_embedding\"] = (\n",
    "    df[\"job_title\"].astype(str) + \" | \" +\n",
    "    df[\"job_description\"].astype(str) + \" | \" +\n",
    "    df[\"tags_clean\"].astype(str)\n",
    ")\n",
    "\n",
    "# Load embedding model (you can also try 'all-MiniLM-L6-v2' for speed)\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(df[\"text_for_embedding\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Save embeddings into dataframe\n",
    "df[\"embeddings\"] = embeddings.tolist()\n",
    "\n",
    "# Save processed file\n",
    "df.to_pickle(\"dataset_with_embeddings.pkl\")  # preserves numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a9a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['tags_clean'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "093f0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          embeddings client_country  \\\n",
      "0  [-0.0010373883415013552, 0.02592027746140957, ...        Germany   \n",
      "1  [0.013640339486300945, 0.07931948453187943, -0...          India   \n",
      "2  [0.05617599934339523, 0.07921624183654785, -0....         France   \n",
      "3  [-0.010524313896894455, 0.04207714647054672, -...          India   \n",
      "4  [0.05351153761148453, 0.013150510378181934, -0...  United States   \n",
      "\n",
      "   rate_fixed  rate_hourly  min_price_usd  max_price_usd  \n",
      "0           1            0            8.8           33.0  \n",
      "1           0            1            9.0           15.0  \n",
      "2           1            0           33.0          275.0  \n",
      "3           1            0           60.0           66.0  \n",
      "4           0            1            5.0           15.0  \n"
     ]
    }
   ],
   "source": [
    "# Select only input + output columns\n",
    "train_df = df[['embeddings', 'client_country', \n",
    "               'rate_fixed', 'rate_hourly', \n",
    "               'min_price_usd', 'max_price_usd']].copy()\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6ffc255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>client_country</th>\n",
       "      <th>rate_fixed</th>\n",
       "      <th>rate_hourly</th>\n",
       "      <th>min_price_usd</th>\n",
       "      <th>max_price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0010373883415013552, 0.02592027746140957, ...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.013640339486300945, 0.07931948453187943, -0...</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.05617599934339523, 0.07921624183654785, -0....</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>275.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.010524313896894455, 0.04207714647054672, -...</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>66.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.05351153761148453, 0.013150510378181934, -0...</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9188</th>\n",
       "      <td>[0.02490326203405857, 0.0824948102235794, -0.0...</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9189</th>\n",
       "      <td>[0.026110423728823662, 0.0825563296675682, -0....</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>750.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9190</th>\n",
       "      <td>[0.037851691246032715, 0.04596949368715286, -0...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.05</td>\n",
       "      <td>16.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>[-0.018802417442202568, 0.06984639167785645, -...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3300.00</td>\n",
       "      <td>5500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9192</th>\n",
       "      <td>[0.03840016573667526, 0.0462418869137764, -0.0...</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.80</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9192 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings  client_country  \\\n",
       "0     [-0.0010373883415013552, 0.02592027746140957, ...         Germany   \n",
       "1     [0.013640339486300945, 0.07931948453187943, -0...           India   \n",
       "2     [0.05617599934339523, 0.07921624183654785, -0....          France   \n",
       "3     [-0.010524313896894455, 0.04207714647054672, -...           India   \n",
       "4     [0.05351153761148453, 0.013150510378181934, -0...   United States   \n",
       "...                                                 ...             ...   \n",
       "9188  [0.02490326203405857, 0.0824948102235794, -0.0...       Argentina   \n",
       "9189  [0.026110423728823662, 0.0825563296675682, -0....  United Kingdom   \n",
       "9190  [0.037851691246032715, 0.04596949368715286, -0...       Australia   \n",
       "9191  [-0.018802417442202568, 0.06984639167785645, -...           Italy   \n",
       "9192  [0.03840016573667526, 0.0462418869137764, -0.0...           India   \n",
       "\n",
       "      rate_fixed  rate_hourly  min_price_usd  max_price_usd  \n",
       "0              1            0           8.80          33.00  \n",
       "1              0            1           9.00          15.00  \n",
       "2              1            0          33.00         275.00  \n",
       "3              1            0          60.00          66.00  \n",
       "4              0            1           5.00          15.00  \n",
       "...          ...          ...            ...            ...  \n",
       "9188           1            0          30.00         250.00  \n",
       "9189           1            0         250.00         750.00  \n",
       "9190           0            1          10.05          16.75  \n",
       "9191           1            0        3300.00        5500.00  \n",
       "9192           0            1           4.80           9.00  \n",
       "\n",
       "[9192 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f150bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for fixed-price projects\n",
    "is_fixed_mask = train_df['rate_fixed'] == 1\n",
    "\n",
    "# Split into two dataframes\n",
    "fixed_df = train_df[is_fixed_mask]\n",
    "hourly_df = train_df[~is_fixed_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae17e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4965c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data with Embeddings ---\n",
      "Successfully loaded 'dataset_with_embeddings.pkl'.\n",
      "\n",
      "--- 2. Preprocessing Data for Training ---\n",
      "Country encoder created and saved to 'country_encoder.joblib'.\n",
      "Split data into 7321 fixed-price and 1871 hourly-rate projects.\n",
      "\n",
      "For Fixed-Price Projects:\n",
      "  Removed 1322 high-budget outliers (prices > $748.75).\n",
      "  Remaining projects for training/testing: 5999\n",
      "\n",
      "For Hourly-Rate Projects:\n",
      "  Removed 149 high-budget outliers (prices > $49.00).\n",
      "  Remaining projects for training/testing: 1722\n",
      "\n",
      "--- Processing Model for Fixed-Price Projects ---\n",
      "Split cleaned data into 4799 for training and 1200 for testing.\n",
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8931 - val_loss: 0.4451\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4506 - val_loss: 0.4001\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4104 - val_loss: 0.4080\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3996 - val_loss: 0.3926\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3835 - val_loss: 0.3936\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3699 - val_loss: 0.3936\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3578 - val_loss: 0.4080\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3497 - val_loss: 0.3928\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3382 - val_loss: 0.3885\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3285 - val_loss: 0.4040\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3258 - val_loss: 0.3957\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3166 - val_loss: 0.3990\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3069 - val_loss: 0.4051\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2982 - val_loss: 0.4020\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2931 - val_loss: 0.4048\n",
      "Epoch 16/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2856 - val_loss: 0.4066\n",
      "Epoch 17/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2738 - val_loss: 0.4068\n",
      "Epoch 18/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2692 - val_loss: 0.4085\n",
      "Epoch 19/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2640 - val_loss: 0.4077\n",
      "Training complete.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Metrics for Fixed-Price Projects ---\n",
      "Test MAE: $65.05\n",
      "Test RMSE: $109.18\n",
      "\n",
      "--- Model saved to fixed_price_model.h5 ---\n",
      "\n",
      "--- Processing Model for Hourly-Rate Projects ---\n",
      "Split cleaned data into 1377 for training and 345 for testing.\n",
      "Epoch 1/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6643 - val_loss: 0.2747\n",
      "Epoch 2/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2648 - val_loss: 0.2433\n",
      "Epoch 3/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2160 - val_loss: 0.2243\n",
      "Epoch 4/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1900 - val_loss: 0.2172\n",
      "Epoch 5/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1694 - val_loss: 0.2072\n",
      "Epoch 6/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1720 - val_loss: 0.2145\n",
      "Epoch 7/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1671 - val_loss: 0.2082\n",
      "Epoch 8/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1597 - val_loss: 0.2023\n",
      "Epoch 9/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1620 - val_loss: 0.2028\n",
      "Epoch 10/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1461 - val_loss: 0.2086\n",
      "Epoch 11/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1416 - val_loss: 0.2044\n",
      "Epoch 12/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1359 - val_loss: 0.1977\n",
      "Epoch 13/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1258 - val_loss: 0.1944\n",
      "Epoch 14/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1282 - val_loss: 0.2064\n",
      "Epoch 15/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1228 - val_loss: 0.1988\n",
      "Epoch 16/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1177 - val_loss: 0.1959\n",
      "Epoch 17/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1127 - val_loss: 0.1969\n",
      "Epoch 18/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1108 - val_loss: 0.2010\n",
      "Epoch 19/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1155 - val_loss: 0.1969\n",
      "Epoch 20/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1049 - val_loss: 0.2001\n",
      "Epoch 21/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1020 - val_loss: 0.2125\n",
      "Epoch 22/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1015 - val_loss: 0.2025\n",
      "Epoch 23/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1039 - val_loss: 0.1979\n",
      "Training complete.\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Metrics for Hourly-Rate Projects ---\n",
      "Test MAE: $5.64\n",
      "Test RMSE: $7.46\n",
      "\n",
      "--- Model saved to hourly_rate_model.h5 ---\n",
      "\n",
      "--- ML Training Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# --- Configuration ---\n",
    "# Make sure the pickle file with your embeddings is in the same folder\n",
    "EMBEDDINGS_FILENAME = 'dataset_with_embeddings.pkl'\n",
    "\n",
    "# --- 1. Load Pre-processed Data ---\n",
    "print(\"--- 1. Loading Data with Embeddings ---\")\n",
    "try:\n",
    "    train_df = pd.read_pickle(EMBEDDINGS_FILENAME)\n",
    "    print(f\"Successfully loaded '{EMBEDDINGS_FILENAME}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: The file '{EMBEDDINGS_FILENAME}' was not found.\")\n",
    "    print(\"Please run your embedding generation script first.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Initial Preprocessing ---\n",
    "print(\"\\n--- 2. Preprocessing Data for Training ---\")\n",
    "# Encode country names into integer IDs\n",
    "country_encoder = LabelEncoder()\n",
    "train_df['country_encoded'] = country_encoder.fit_transform(train_df['client_country'])\n",
    "num_countries = len(country_encoder.classes_)\n",
    "\n",
    "# Save the fitted LabelEncoder for use in the Flask app\n",
    "joblib.dump(country_encoder, 'country_encoder.joblib')\n",
    "print(\"Country encoder created and saved to 'country_encoder.joblib'.\")\n",
    "\n",
    "# Split into two separate dataframes\n",
    "is_fixed_mask = train_df['rate_fixed'] == 1\n",
    "fixed_df = train_df[is_fixed_mask].copy()\n",
    "hourly_df = train_df[~is_fixed_mask].copy()\n",
    "print(f\"Split data into {len(fixed_df)} fixed-price and {len(hourly_df)} hourly-rate projects.\\n\")\n",
    "\n",
    "\n",
    "# --- 3. Identify and Remove Outliers from Each Dataset ---\n",
    "def remove_outliers(df, column_name, df_name):\n",
    "    \"\"\"Identifies and removes outliers based on the IQR method.\"\"\"\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    num_outliers = df[df[column_name] > upper_bound].shape[0]\n",
    "    \n",
    "    # Filter the dataframe to keep only non-outliers\n",
    "    df_cleaned = df[df[column_name] <= upper_bound].copy()\n",
    "    \n",
    "    print(f\"For {df_name}:\")\n",
    "    print(f\"  Removed {num_outliers} high-budget outliers (prices > ${upper_bound:,.2f}).\")\n",
    "    print(f\"  Remaining projects for training/testing: {len(df_cleaned)}\\n\")\n",
    "    return df_cleaned\n",
    "\n",
    "fixed_df_cleaned = remove_outliers(fixed_df, 'max_price_usd', 'Fixed-Price Projects')\n",
    "hourly_df_cleaned = remove_outliers(hourly_df, 'max_price_usd', 'Hourly-Rate Projects')\n",
    "\n",
    "\n",
    "# --- 4. Define Model Architecture ---\n",
    "embedding_dim = np.array(train_df['embeddings'].iloc[0]).shape[0]\n",
    "\n",
    "def build_regressor(embedding_dim, num_countries):\n",
    "    \"\"\"Builds a robust regression model.\"\"\"\n",
    "    text_in = layers.Input(shape=(embedding_dim,), name=\"text_embeddings\")\n",
    "    country_in = layers.Input(shape=(1,), name=\"country\")\n",
    "    \n",
    "    country_emb = layers.Embedding(input_dim=num_countries + 1, output_dim=16)(country_in)\n",
    "    country_emb = layers.Flatten()(country_emb)\n",
    "    \n",
    "    concatenated = layers.Concatenate()([text_in, country_emb])\n",
    "    \n",
    "    x = layers.Dense(128, activation='relu')(concatenated)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    output = layers.Dense(2, activation='linear', name='price_range')(x)\n",
    "    \n",
    "    model = Model(inputs=[text_in, country_in], outputs=output)\n",
    "    return model\n",
    "\n",
    "# --- 5. Train and Evaluate a Model for Each Dataset ---\n",
    "def train_and_evaluate_model(df, df_name, save_filename):\n",
    "    \"\"\"Splits data, trains a model, and evaluates it.\"\"\"\n",
    "    print(f\"--- Processing Model for {df_name} ---\")\n",
    "    \n",
    "    # Split Data\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print(f\"Split cleaned data into {len(train_data)} for training and {len(test_data)} for testing.\")\n",
    "    \n",
    "    # Prepare Training Data\n",
    "    y_log_train = np.log1p(train_data[['min_price_usd', 'max_price_usd']].values)\n",
    "    X_train = {\n",
    "        \"text_embeddings\": np.array(train_data['embeddings'].tolist()),\n",
    "        \"country\": train_data['country_encoded'].values\n",
    "    }\n",
    "    \n",
    "    # Prepare Test/Validation Data\n",
    "    y_log_test = np.log1p(test_data[['min_price_usd', 'max_price_usd']].values)\n",
    "    X_test = {\n",
    "        \"text_embeddings\": np.array(test_data['embeddings'].tolist()),\n",
    "        \"country\": test_data['country_encoded'].values\n",
    "    }\n",
    "    \n",
    "    # Build and Compile\n",
    "    regressor = build_regressor(embedding_dim, num_countries)\n",
    "    regressor.compile(optimizer=Adam(learning_rate=0.001), loss='huber')\n",
    "    \n",
    "    # Train\n",
    "    stop_early = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    regressor.fit(X_train, y_log_train,\n",
    "                  validation_data=(X_test, y_log_test),\n",
    "                  epochs=100, batch_size=32, callbacks=[stop_early], verbose=1)\n",
    "    print(\"Training complete.\")\n",
    "    \n",
    "    # Evaluate\n",
    "    y_test_actual = test_data[['min_price_usd', 'max_price_usd']].values\n",
    "    log_preds = regressor.predict(X_test)\n",
    "    final_dollar_preds = np.expm1(log_preds)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_actual, final_dollar_preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_actual, final_dollar_preds))\n",
    "    \n",
    "    print(f\"\\n--- Final Metrics for {df_name} ---\")\n",
    "    print(f\"Test MAE: ${mae:,.2f}\")\n",
    "    print(f\"Test RMSE: ${rmse:,.2f}\\n\")\n",
    "\n",
    "    # Save the final model in the .h5 format\n",
    "    regressor.save(save_filename)\n",
    "    print(f\"--- Model saved to {save_filename} ---\\n\")\n",
    "\n",
    "# Run the process for both fixed-price and hourly-rate projects\n",
    "train_and_evaluate_model(fixed_df_cleaned, \"Fixed-Price Projects\", \"fixed_price_model.h5\")\n",
    "train_and_evaluate_model(hourly_df_cleaned, \"Hourly-Rate Projects\", \"hourly_rate_model.h5\")\n",
    "\n",
    "print(\"--- ML Training Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f605a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fixed_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mfixed_model\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed_price_model_new.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m hourly_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhourly_rate_model_new.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fixed_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb8b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n",
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models converted successfully to Keras 3 format\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# Load old H5 models (using tf.keras inside keras 3 is fine)\n",
    "old_fixed = keras.models.load_model(\"fixed_price_model.h5\", compile=False)\n",
    "old_hourly = keras.models.load_model(\"hourly_rate_model.h5\", compile=False)\n",
    "\n",
    "# Save them in new Keras 3 format\n",
    "old_fixed.save(\"fixed_price_model_new.keras\", save_format=\"keras\")\n",
    "old_hourly.save(\"hourly_rate_model_new.keras\", save_format=\"keras\")\n",
    "\n",
    "print(\"✅ Models converted successfully to Keras 3 format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b758e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freelancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
